# ğŸ¤– AgentFlow - Personal AI Assistant

**AgentFlow** is a personal AI assistant built on large language models, currently in M0 phase (runnable skeleton) with basic conversation capabilities.

**[ä¸­æ–‡è¯´æ˜](#ä¸­æ–‡è¯´æ˜)** | [English Description](#english-description)

## English Description

### âœ¨ Features

- **Multi-Model Support**: Seamlessly switch between Gemini and DeepSeek models
- **Unified Interface**: Consistent LLM calling interface with timeout and retry mechanisms
- **Comprehensive Logging**: INFO/DEBUG level logging with file and console output
- **Flexible Configuration**: Environment variables and .env file configuration
- **Modern UI**: Gradio-based chat interface
- **Modular Design**: Clean code structure for easy extension

### ğŸš€ Quick Start

#### 1. Environment Setup

```bash
# Clone or download the project
cd /path/to/AgentFlow

# Install dependencies
pip install -r requirements.txt
```

#### 2. Configure API Keys

Copy and edit the configuration file:

```bash
cp .env.example .env
```

Edit the `.env` file to set your API keys:

```env
# Choose the model provider
MODEL_PROVIDER=deepseek  # or gemini

# Set API keys (choose one or both)
GEMINI_API_KEY=your_gemini_api_key_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here
```

#### 3. Launch the System

```bash
# Start Gradio interface
python main.py

# Or run UI directly
python ui_gradio.py
```

The system will start at `http://localhost:7860`, where you can access the chat interface in your browser.

### ğŸ“ Project Structure

```
AgentFlow/
â”œâ”€â”€ main.py                 # Main entry point
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ .env.example           # Configuration template
â”œâ”€â”€ README.md              # Documentation
â”œâ”€â”€ config.py              # Configuration management
â”œâ”€â”€ logger.py              # Logging system
â”œâ”€â”€ llm_interface.py       # LLM interface abstraction
â”œâ”€â”€ agent_core.py          # Agent core logic
â”œâ”€â”€ ui_gradio.py           # Gradio user interface
â”œâ”€â”€ test_keys.py           # API key testing script
â”œâ”€â”€ demo_models.py         # Model switching demo
â”œâ”€â”€ rag_vector_store.py    # RAG retrieval (placeholder)
â”œâ”€â”€ tool_registry.py       # Tool registry (placeholder)
â”œâ”€â”€ tools/                 # Tool scripts directory
â”‚   â”œâ”€â”€ tool_weather.py    # Weather tool (placeholder)
â”‚   â”œâ”€â”€ tool_datetime.py   # DateTime tool (placeholder)
â”‚   â”œâ”€â”€ tool_calculator.py # Calculator tool (placeholder)
â”‚   â”œâ”€â”€ tool_calendar.py   # Calendar tool (placeholder)
â”‚   â”œâ”€â”€ tool_email.py      # Email tool (placeholder)
â”‚   â”œâ”€â”€ tool_websearch.py  # Web search tool (placeholder)
â”‚   â””â”€â”€ tool_file_reader.py # File reader tool (placeholder)
â””â”€â”€ bot_telegram.py        # Telegram Bot (placeholder)
```

### âš™ï¸ Configuration

#### API Key Setup

**ğŸ“ Location: `.env` file in project root**

1. Copy the configuration file:
```bash
cp .env.example .env
```

2. Edit the `.env` file to set your API keys:

```env
# Choose model provider
MODEL_PROVIDER=deepseek  # or gemini

# Set API keys (choose one or both)
GEMINI_API_KEY=your_gemini_api_key_here
DEEPSEEK_API_KEY=your_deepseek_api_key_here
```

#### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `MODEL_PROVIDER` | `gemini` | Model provider: `gemini` or `deepseek` |
| `GEMINI_API_KEY` | - | **Required**: Gemini API key |
| `DEEPSEEK_API_KEY` | - | **Required**: DeepSeek API key |
| `DEEPSEEK_BASE_URL` | `https://api.deepseek.com` | DeepSeek API endpoint |
| `RAG_ENABLED` | `false` | Enable RAG functionality |
| `TOOLS_ENABLED` | `false` | Enable tool functionality |
| `LOG_LEVEL` | `INFO` | Log level: `INFO` or `DEBUG` |
| `MAX_TOKENS` | `4096` | Maximum tokens |
| `TEMPERATURE` | `0.7` | Generation temperature |
| `TIMEOUT_SECONDS` | `30` | Request timeout |
| `MAX_RETRIES` | `3` | Maximum retries |

#### ğŸ”‘ Get API Keys

- **Gemini API Key**:
  - Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
  - Create a new API key
  - **Note**: Free tier has strict quota limits, consider upgrading to paid tier

- **DeepSeek API Key**:
  - Visit [DeepSeek Platform](https://platform.deepseek.com/)
  - Register and create an API key
  - **Recommended**: DeepSeek offers very affordable pricing

#### âš ï¸ API Quota Notes

- **Gemini Free Tier**: Strict rate limits and daily quotas
- **DeepSeek**: More generous free quotas, recommended for primary use
- Switch models in `.env` if you hit quota limits

### ğŸ”§ Development

#### Independent Testing

The system supports independent testing in notebooks without full API key setup:

```python
# 1. Test configuration system
from config import get_config
config = get_config()
config.validate(require_api_keys=False)  # Skip API key validation

# 2. Test logging system
from logger import setup_logging, get_logger
setup_logging("DEBUG")
logger = get_logger()

# 3. Test LLM interface (requires API keys)
from llm_interface import create_llm_interface_with_keys
llm = create_llm_interface_with_keys()
result = await llm.generate("Hello, world!")

# 4. Test Agent core
from agent_core import AgentCore
agent = AgentCore()
agent.set_llm_interface(llm)
result = await agent.process("Hello")
```

#### Adding New LLM Providers

1. Inherit from `LLMProvider` class in `llm_interface.py`
2. Implement the `generate` method
3. Add the new provider in `LLMInterface._create_provider()`

#### Extending Agent Features

1. Add new logic in `agent_core.py`'s `process` method
2. Implement tool calling and RAG retrieval
3. Update configuration switches

#### Customizing UI

Modify the interface layout and styles in `ui_gradio.py`.

### ğŸ“ Usage Instructions

1. **Basic Chat**: Type your message and press Enter or click Send
2. **System Info**: Click "System Info" panel to view current configuration
3. **Clear History**: Click "Clear History" to reset chat
4. **Log Viewing**: Check console output or `logs/agent.log` file

### ğŸš§ Current Limitations

- Basic conversation only
- Tool calling and RAG not yet implemented
- Telegram Bot not developed
- Single-turn conversations (no context memory)

### ğŸ”„ Future Roadmap

- [ ] M1: Implement tool calling system
- [ ] M2: Integrate RAG retrieval
- [ ] M3: Add multi-turn conversation memory
- [ ] M4: Implement Telegram Bot
- [ ] M5: Advanced features and optimizations

---

## ä¸­æ–‡è¯´æ˜

### âœ¨ åŠŸèƒ½ç‰¹æ€§

- **å¤šæ¨¡å‹æ”¯æŒ**: æ”¯æŒGeminiå’ŒDeepSeekæ¨¡å‹æ— ç¼åˆ‡æ¢
- **ç»Ÿä¸€æ¥å£**: ç»Ÿä¸€çš„LLMè°ƒç”¨æ¥å£ï¼Œæ”¯æŒè¶…æ—¶é‡è¯•
- **å®Œå–„æ—¥å¿—**: INFO/DEBUGä¸¤æ¡£æ—¥å¿—ï¼Œæ”¯æŒæ–‡ä»¶å’Œæ§åˆ¶å°è¾“å‡º
- **é…ç½®çµæ´»**: é€šè¿‡ç¯å¢ƒå˜é‡å’Œ.envæ–‡ä»¶è¿›è¡Œé…ç½®
- **ç°ä»£åŒ–UI**: åŸºäºGradioçš„èŠå¤©ç•Œé¢
- **æ¨¡å—åŒ–è®¾è®¡**: æ¸…æ™°çš„ä»£ç ç»“æ„ï¼Œä¾¿äºæ‰©å±•

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®åˆ°æœ¬åœ°
cd /path/to/AgentFlow

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### 2. é…ç½®APIå¯†é’¥

å¤åˆ¶å¹¶ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼š

```bash
cp .env.example .env
```

ç¼–è¾‘`.env`æ–‡ä»¶ï¼Œè®¾ç½®ä½ çš„APIå¯†é’¥ï¼š

```env
# é€‰æ‹©ä½¿ç”¨çš„æ¨¡å‹æä¾›å•†
MODEL_PROVIDER=deepseek  # æˆ– gemini

# è®¾ç½®APIå¯†é’¥ï¼ˆä»»é€‰å…¶ä¸€æˆ–å…¨éƒ¨è®¾ç½®ï¼‰
GEMINI_API_KEY=ä½ çš„Gemini_APIå¯†é’¥
DEEPSEEK_API_KEY=ä½ çš„DeepSeek_APIå¯†é’¥
```

#### 3. å¯åŠ¨ç³»ç»Ÿ

```bash
# å¯åŠ¨Gradioç•Œé¢
python main.py

# æˆ–è€…ç›´æ¥è¿è¡ŒUI
python ui_gradio.py
```

ç³»ç»Ÿå°†åœ¨ `http://localhost:7860` å¯åŠ¨ï¼Œä½ å¯ä»¥åœ¨æµè§ˆå™¨ä¸­è®¿é—®èŠå¤©ç•Œé¢ã€‚

### ğŸ”‘ è·å–APIå¯†é’¥

- **Gemini APIå¯†é’¥**:
  - è®¿é—® [Google AI Studio](https://makersuite.google.com/app/apikey)
  - åˆ›å»ºæ–°çš„APIå¯†é’¥
  - **æ³¨æ„**: å…è´¹ç‰ˆæœ‰ä¸¥æ ¼çš„é…é¢é™åˆ¶ï¼Œå¯èƒ½éœ€è¦å‡çº§åˆ°ä»˜è´¹ç‰ˆ

- **DeepSeek APIå¯†é’¥**:
  - è®¿é—® [DeepSeekå¹³å°](https://platform.deepseek.com/)
  - æ³¨å†Œè´¦æˆ·å¹¶åˆ›å»ºAPIå¯†é’¥
  - **æ¨è**: DeepSeekæä¾›éå¸¸ä¾¿å®œçš„æ¥å£ä»·æ ¼

### âš ï¸ APIé…é¢è¯´æ˜

- **Geminiå…è´¹ç‰ˆ**: æœ‰ä¸¥æ ¼çš„è¯·æ±‚é¢‘ç‡å’Œæ¯æ—¥é™åˆ¶
- **DeepSeek**: æä¾›æ›´å……è¶³çš„å…è´¹é¢åº¦ï¼Œæ¨èä¼˜å…ˆä½¿ç”¨
- å¦‚æœé‡åˆ°é…é¢é™åˆ¶ï¼Œå¯ä»¥åœ¨ `.env` æ–‡ä»¶ä¸­åˆ‡æ¢ `MODEL_PROVIDER` åˆ°å¦ä¸€ä¸ªæ¨¡å‹

### ğŸ”§ å¼€å‘è¯´æ˜

#### ç‹¬ç«‹æµ‹è¯•å„ä¸ªåŠŸèƒ½ç‚¹

ç³»ç»Ÿè®¾è®¡æ”¯æŒåœ¨notebookä¸­è¿›è¡Œç‹¬ç«‹æµ‹è¯•ï¼Œæ— éœ€å®Œæ•´çš„APIå¯†é’¥è®¾ç½®ï¼š

```python
# 1. æµ‹è¯•é…ç½®ç³»ç»Ÿ
from config import get_config
config = get_config()
config.validate(require_api_keys=False)  # ä¸éªŒè¯APIå¯†é’¥

# 2. æµ‹è¯•æ—¥å¿—ç³»ç»Ÿ
from logger import setup_logging, get_logger
setup_logging("DEBUG")
logger = get_logger()

# 3. æµ‹è¯•LLMæ¥å£ï¼ˆéœ€è¦APIå¯†é’¥ï¼‰
from llm_interface import create_llm_interface_with_keys
llm = create_llm_interface_with_keys()
await llm.generate("Hello, world!")

# 4. æµ‹è¯•Agentæ ¸å¿ƒ
from agent_core import AgentCore
agent = AgentCore()
agent.set_llm_interface(llm)
result = await agent.process("ä½ å¥½")
```

## ğŸ¤ Contributing

Welcome to submit Issues and Pull Requests to improve this project!

## ğŸ“„ License

MIT License
