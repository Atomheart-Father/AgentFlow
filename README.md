# ğŸ¤– AI Personal Assistant - M0 Phase

A personal AI assistant based on large language models, currently in M0 phase (runnable skeleton), supporting basic conversation functionality.

## âœ¨ Features

- **Multi-Model Support**: Support switching between Gemini and DeepSeek models
- **Unified Interface**: Unified LLM calling interface with timeout retry
- **Complete Logging**: INFO/DEBUG level logging, supporting file and console output
- **Flexible Configuration**: Configure through environment variables and .env file
- **Modern UI**: Chat interface based on Gradio
- **Modular Design**: Clear code structure for easy extension

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Clone or download the project locally
cd /path/to/personal_agent

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure API Keys

Copy and edit the configuration file:

```bash
cp .env.example .env
```

Edit the `.env` file and set your API keys:

```env
# Choose model provider
MODEL_PROVIDER=gemini  # or deepseek

# Gemini configuration
GEMINI_API_KEY=your_gemini_api_key_here

# DeepSeek configuration
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_BASE_URL=https://api.deepseek.com

# Other configurations can remain default
```

### 3. Start the System

```bash
# Option 1: Start Gradio interface (legacy)
python main.py

# Option 2: Run Gradio UI directly (legacy)
python ui_gradio.py

# Option 3: Start Chainlit UI (æ¨è - æ”¯æŒçœŸÂ·æµå¼å’Œæ™ºèƒ½åˆ†æµ)
chainlit run ui_chainlit.py -w
```

- **Gradio UI**: ä¼ ç»Ÿç•Œé¢ï¼Œå¯åŠ¨åœ¨ `http://localhost:7860`
- **Chainlit UI** (æ¨è): ç°ä»£åŒ–æµå¼ç•Œé¢ï¼Œå¯åŠ¨åœ¨ `http://localhost:8000`ï¼Œæ”¯æŒï¼š
  - âœ… çœŸÂ·æµå¼å“åº”ï¼ˆé€tokenæ˜¾ç¤ºï¼‰
  - âœ… æ™ºèƒ½åˆ†æµï¼ˆç®€å•é—®ç­”vså¤æ‚ç¼–æ’ï¼‰
  - âœ… AskUserç»­è·‘ï¼ˆé¿å…è¶…æ—¶ï¼‰
  - âœ… äº‹ä»¶åˆ†æµï¼ˆçŠ¶æ€/å·¥å…·è½¨è¿¹è¿›ä¾§æ ï¼‰

## ğŸ¯ æœ¬åœ°å¿«é€Ÿè¯•è·‘

### ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install -r requirements.txt

# å®‰è£… Chainlit UI å’Œ RAG ç›¸å…³ä¾èµ–
pip install chainlit chromadb sentence-transformers

# å¯é€‰ï¼šè®¾ç½®æ¡Œé¢ç›®å½•ç¯å¢ƒå˜é‡
export DESKTOP_DIR=~/Desktop/AgentFlow
```

### é…ç½® API å¯†é’¥

ç¼–è¾‘ `.env` æ–‡ä»¶è®¾ç½® API å¯†é’¥ï¼š

```env
# é€‰æ‹©æ¨¡å‹æä¾›å•†
MODEL_PROVIDER=deepseek  # æˆ– gemini

# DeepSeek é…ç½®ï¼ˆæ¨èï¼‰
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_BASE_URL=https://api.deepseek.com

# Gemini é…ç½®ï¼ˆå¯é€‰ï¼‰
GEMINI_API_KEY=your_gemini_api_key_here

# å¯ç”¨åŠŸèƒ½
RAG_ENABLED=true
TOOLS_ENABLED=true
USE_M3_ORCHESTRATOR=true
```

### å¯é€‰ï¼šæ„å»º RAG ç´¢å¼•

```bash
# åˆ›å»ºæ–‡æ¡£ç›®å½•
mkdir -p ./notes

# å°†ä½ çš„ .md/.txt æ–‡æ¡£æ”¾å…¥ ./notes/ ç›®å½•

# æ„å»ºç´¢å¼•
python -m rag.ingest --src ./notes
```

### å¯åŠ¨ç°ä»£åŒ– UI

```bash
# ä½¿ç”¨ Chainlit å¯åŠ¨ï¼ˆæ¨èï¼‰
chainlit run ui_chainlit.py -w

# æˆ–ä½¿ç”¨ä¼ ç»Ÿ Gradio UI
python ui_gradio.py
```

### æµ‹è¯•åŠŸèƒ½

1. **è®¿é—®æµè§ˆå™¨**ï¼šæ‰“å¼€ `http://localhost:7860`
2. **çœŸÂ·æµå¼æµ‹è¯•**ï¼šå‘é€æ¶ˆæ¯ï¼Œè§‚å¯Ÿå†…å®¹é€æ®µæ˜¾ç¤º
3. **äº‹ä»¶åˆ†æµæµ‹è¯•**ï¼šæŸ¥çœ‹ä¾§æ çš„è¿è¡Œæ—¥å¿—å’Œå·¥å…·è½¨è¿¹
4. **AskUser ç»­è·‘æµ‹è¯•**ï¼š
   - å‘é€éœ€è¦ç”¨æˆ·è¾“å…¥çš„æŸ¥è¯¢ï¼ˆå¦‚"å¸®æˆ‘è§„åˆ’æ˜å¤©å‡ºè¡Œ"ï¼‰
   - ç³»ç»Ÿä¼šè¯¢é—®åŸå¸‚ç­‰ä¿¡æ¯
   - ç›´æ¥åœ¨è¾“å…¥æ¡†å›å¤ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç»­è·‘ä»»åŠ¡
5. **RAG æœç´¢æµ‹è¯•**ï¼šå¦‚æœæœ‰æ–‡æ¡£ç´¢å¼•ï¼Œå¯ä»¥æµ‹è¯•æ–‡æ¡£æœç´¢åŠŸèƒ½

### æ³¨æ„äº‹é¡¹

- **è¿æ¥ç¨³å®š**ï¼šChainlit é»˜è®¤å¯ç”¨ WebSocketï¼Œå¦‚æ–­çº¿åˆ·æ–°é¡µé¢è‡ªåŠ¨é‡è¿
- **ä¼šè¯çŠ¶æ€**ï¼šåŒä¸€ä¼šè¯ä¸­çš„ AskUser ä¼šè¢«è‡ªåŠ¨ç»­è·‘
- **å®‰å…¨æ²™ç®±**ï¼šæ–‡ä»¶å†™å…¥ä»…é™äº `DESKTOP_DIR` ç›®å½•
- **æ—¥å¿—ç›‘æ§**ï¼šå…³é”®äº‹ä»¶è®°å½•åœ¨ `logs/errors.jsonl`
- **æ–°ä»»åŠ¡å¼€å§‹**ï¼šè¾“å…¥"æ–°çš„é—®é¢˜"ã€"é‡æ¥"ç­‰å…³é”®è¯å¯é‡ç½®ä¼šè¯

## ğŸ“ Project Structure

```
personal_agent/
â”œâ”€â”€ main.py                 # Main startup file
â”œâ”€â”€ requirements.txt        # Dependencies list
â”œâ”€â”€ .env.example           # Configuration template
â”œâ”€â”€ README.md              # Documentation
â”œâ”€â”€ config.py              # Configuration management
â”œâ”€â”€ logger.py              # Logging system
â”œâ”€â”€ llm_interface.py       # LLM interface abstraction
â”œâ”€â”€ agent_core.py          # Agent core logic
â”œâ”€â”€ ui_gradio.py           # Gradio user interface
â”œâ”€â”€ rag_vector_store.py    # RAG retrieval module (reserved)
â”œâ”€â”€ tool_registry.py       # Tool registration module (reserved)
â”œâ”€â”€ tools/                 # Tool scripts directory
â”‚   â”œâ”€â”€ tool_weather.py    # Weather query tool (reserved)
â”‚   â”œâ”€â”€ tool_datetime.py   # Date time tool (reserved)
â”‚   â”œâ”€â”€ tool_calculator.py # Calculator tool (reserved)
â”‚   â”œâ”€â”€ tool_calendar.py   # Calendar query tool (reserved)
â”‚   â”œâ”€â”€ tool_email.py      # Email reading tool (reserved)
â”‚   â”œâ”€â”€ tool_websearch.py  # Web search tool (reserved)
â”‚   â””â”€â”€ tool_file_reader.py # File reading tool (reserved)
â””â”€â”€ bot_telegram.py        # Telegram Bot (reserved)
```

## âš™ï¸ Configuration Guide

### API Key Setup

**ğŸ“ Location: `.env` file in project root directory**

1. Copy the configuration file:
```bash
cp .env.example .env
```

2. Edit the `.env` file and set your API keys:

```env
# Choose model provider to use
MODEL_PROVIDER=gemini  # or deepseek

# Set API keys (choose one or set all)
GEMINI_API_KEY=your_Gemini_API_key
DEEPSEEK_API_KEY=your_DeepSeek_API_key
```

### Complete Environment Variables List

| Variable Name | Default Value | Description |
|---------------|---------------|-------------|
| `MODEL_PROVIDER` | `gemini` | Model provider: `gemini` or `deepseek` |
| `GEMINI_API_KEY` | - | **Required**: Gemini API key |
| `DEEPSEEK_API_KEY` | - | **Required**: DeepSeek API key |
| `DEEPSEEK_BASE_URL` | `https://api.deepseek.com` | DeepSeek API address |
| `RAG_ENABLED` | `false` | Enable RAG functionality |
| `TOOLS_ENABLED` | `false` | Enable tool functionality |
| `LOG_LEVEL` | `INFO` | Log level: `INFO` or `DEBUG` |
| `MAX_TOKENS` | `4096` | Maximum token count |
| `TEMPERATURE` | `0.7` | Generation temperature |
| `TIMEOUT_SECONDS` | `30` | Request timeout time |
| `MAX_RETRIES` | `3` | Maximum retry count |

### ğŸ”‘ Getting API Keys

- **Gemini API Key**:
  - Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
  - Create a new API key
  - **Note**: Free version has strict quota limits, may need to upgrade to paid version

- **DeepSeek API Key**:
  - Visit [DeepSeek Platform](https://platform.deepseek.com/)
  - Register account and create API key
  - **Recommended**: DeepSeek provides very cheap API pricing

### âš ï¸ API Quota Notes

- **Gemini Free Version**: Has strict request frequency and daily limits
- **DeepSeek**: Provides more generous free quota, recommended for priority use
- If you encounter quota limits, you can switch `MODEL_PROVIDER` to another model in the `.env` file

### Logging System

Log files are saved in `logs/agent.log`, supporting:
- Console output (colored)
- File output (structured)
- Auto rotation (10MB)
- Retention for 7 days

## ğŸ”§ Development Guide

### Independent Testing of Each Feature

The system is designed to support independent testing in notebooks without complete API key setup:

```python
# 1. Test configuration system
from config import get_config
config = get_config()
config.validate(require_api_keys=False)  # Don't validate API keys

# 2. Test logging system
from logger import setup_logging, get_logger
setup_logging("DEBUG")
logger = get_logger()

# 3. Test LLM interface (requires API keys)
from llm_interface import create_llm_interface_with_keys
llm = create_llm_interface_with_keys()
await llm.generate("Hello, world!")

# 4. Test Agent core
from agent_core import AgentCore
agent = AgentCore()
agent.set_llm_interface(llm)  # Set LLM interface
result = await agent.process("Hello")
```

### Adding New LLM Providers

1. Inherit `LLMProvider` class in `llm_interface.py`
2. Implement `generate` method
3. Add new provider in `LLMInterface._create_provider()`

### Extending Agent Functionality

1. Add new logic in `process` method of `agent_core.py`
2. Implement tool calling and RAG retrieval
3. Update configuration switches

### Customizing UI

Modify interface layout and styles in `ui_gradio.py`.

## ğŸ“ Usage Instructions

1. **Basic Conversation**: Enter your question in the input box, click send or press Enter
2. **View System Information**: Click the "System Information" collapsible panel to view current configuration
3. **Clear History**: Click the "Clear History" button to clear chat records
4. **View Logs**: Check console output or `logs/agent.log` file

## ğŸš§ Current Limitations

- Only supports basic conversation functionality
- Tool calling and RAG functionality not yet implemented
- Telegram Bot not yet developed
- Only supports single-turn conversations (no context memory)

## ğŸ”„ Future Plans

- [ ] M1 Phase: Implement tool calling system
- [ ] M2 Phase: Integrate RAG retrieval
- [ ] M3 Phase: Add multi-turn conversation memory
- [ ] M4 Phase: Implement Telegram Bot
- [ ] M5 Phase: Advanced features and optimizations

## ğŸ¤ Contributing

Welcome to submit Issues and Pull Requests to improve this project!

## ğŸ“„ License

MIT License
