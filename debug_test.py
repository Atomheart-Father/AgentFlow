#!/usr/bin/env python3
"""
è°ƒè¯•å·¥å…·è°ƒç”¨åŠŸèƒ½çš„æµ‹è¯•è„šæœ¬
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

async def test_tools():
    """æµ‹è¯•å·¥å…·è°ƒç”¨åŠŸèƒ½"""
    print("=== å·¥å…·è°ƒç”¨åŠŸèƒ½è°ƒè¯•æµ‹è¯• ===\n")

    try:
        # 1. æµ‹è¯•é…ç½®
        from config import get_config
        config = get_config()
        print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
        print(f"   æ¨¡å‹æä¾›å•†: {config.model_provider}")
        print(f"   å·¥å…·åŠŸèƒ½: {'å¯ç”¨' if config.tools_enabled else 'ç¦ç”¨'}")
        print(f"   DeepSeekæ¨¡å‹: {getattr(config, 'deepseek_model', 'é»˜è®¤')}")

        # 2. æµ‹è¯•å·¥å…·æ³¨å†Œ
        print("\n--- æµ‹è¯•å·¥å…·æ³¨å†Œ ---")
        from tool_registry import get_tools, execute_tool, to_openai_tools

        tools = get_tools()
        print("âœ… å·¥å…·æ³¨å†ŒæˆåŠŸ")
        print(f"   å·¥å…·æ•°é‡: {len(tools)}")
        print(f"   å·¥å…·åç§°: {[t.name for t in tools]}")

        # 3. æµ‹è¯•å•ä¸ªå·¥å…·è°ƒç”¨
        print("\n--- æµ‹è¯• time_now å·¥å…· ---")
        result = execute_tool("time_now", tools)
        print("âœ… time_nowå·¥å…·æ‰§è¡ŒæˆåŠŸ")
        print(f"   ç»“æœ: {result}")

        # 4. æµ‹è¯•LLMæ¥å£
        print("\n--- æµ‹è¯• LLM æ¥å£ ---")
        from llm_interface import create_llm_interface_with_keys

        llm = create_llm_interface_with_keys()
        print("âœ… LLMæ¥å£åˆ›å»ºæˆåŠŸ")
        print(f"   æä¾›è€…ç±»å‹: {type(llm.provider)}")

        # 5. æµ‹è¯•ç®€å•ç”Ÿæˆ
        print("\n--- æµ‹è¯•ç®€å•æ–‡æœ¬ç”Ÿæˆ ---")
        simple_result = await llm.generate("Hello, how are you?")
        print("âœ… ç®€å•ç”ŸæˆæˆåŠŸ")
        print(f"   å“åº”: {simple_result.content[:100]}...")

        # 6. æµ‹è¯•AgentCoreï¼ˆä½¿ç”¨å·²åˆ›å»ºçš„LLMå®ä¾‹ï¼‰
        print("\n--- æµ‹è¯• AgentCore ---")
        from agent_core import AgentCore

        agent = AgentCore(llm_interface=llm)  # ä½¿ç”¨å·²åˆ›å»ºçš„LLMå®ä¾‹
        print("âœ… AgentCoreåˆ›å»ºæˆåŠŸ")
        print(f"   å·¥å…·æ•°é‡: {len(agent.tools)}")

        # 7. ç›´æ¥æµ‹è¯•LLMå·¥å…·è°ƒç”¨ï¼ˆç»•è¿‡AgentCoreï¼‰
        print("\n--- ç›´æ¥æµ‹è¯•LLMå·¥å…·è°ƒç”¨ ---")

        # æ„å»ºå·¥å…·schema
        from tool_registry import to_openai_tools
        tools_schema = to_openai_tools(agent.tools)

        # æ„å»ºæ¶ˆæ¯
        messages = [
            {"role": "system", "content": "You are a helpful assistant. Use tools when needed."},
            {"role": "user", "content": "What time is it now?"}
        ]

        # æµ‹è¯•ç›´æ¥LLMå·¥å…·è°ƒç”¨
        try:
            tool_result = await llm.generate(
                messages=messages,
                tools_schema=tools_schema
            )
            print("âœ… ç›´æ¥LLMè°ƒç”¨å®Œæˆ")
            print(f"   å“åº”: {tool_result.content[:200]}...")
            print(f"   æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨: {tool_result.function_calls is not None}")
            if tool_result.function_calls:
                print(f"   å·¥å…·è°ƒç”¨è¯¦æƒ…: {tool_result.function_calls}")
            else:
                print("   âŒ æ²¡æœ‰è§¦å‘å·¥å…·è°ƒç”¨")
        except Exception as e:
            print(f"âŒ ç›´æ¥LLMè°ƒç”¨å¤±è´¥: {e}")
            print("   è·³è¿‡å·¥å…·è°ƒç”¨è¯¦æƒ…")

        # 8. æµ‹è¯•AgentCoreï¼ˆç®€åŒ–ç³»ç»Ÿæç¤ºè¯ï¼‰
        print("\n--- æµ‹è¯•AgentCoreï¼ˆç®€åŒ–æç¤ºè¯ï¼‰ ---")

        # åˆ›å»ºæ›´ç®€å•çš„ç³»ç»Ÿæç¤ºè¯
        simple_agent = AgentCore(llm_interface=llm)
        simple_agent._build_system_prompt = lambda: "You are a helpful assistant. For time questions, call time_now tool."

        simple_result = await simple_agent.process("What time is it now?")
        print("âœ… ç®€åŒ–AgentCoreæµ‹è¯•å®Œæˆ")
        print(f"   å“åº”: {simple_result['response'][:200]}...")
        print(f"   å·¥å…·è°ƒç”¨è½¨è¿¹: {simple_result['metadata'].get('tool_call_trace', [])}")

        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_tools())
